{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Project 3] 반도체 공정 데이터를 활용한 공정 이상 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로젝트 목표\n",
    "- 반도체 공정 데이터 분석을 통하여 공정 이상을 예측하는 분류 모델 수행\n",
    "- 공정 이상에 영향을 미치는 요소들에 대한 데이터 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로젝트 목차\n",
    "\n",
    "1. **데이터 읽기:** 반도체 공정(SECOM) 데이터를 불러오고 Dataframe 구조를 확인<br>\n",
    "\n",
    "\n",
    "2. **데이터 정제:** 비어 있는 데이터 또는 쓸모 없는 데이터를 대체<br>\n",
    "\n",
    "\n",
    "3. **데이터 시각화:** 변수 시각화를 통하여 분포 파악<br>\n",
    "    3.1. Pass/Fail 시각화<br>\n",
    "    3.2. 센서 데이터 시각화 하기<br>\n",
    "    3.3. 59번 센서 데이터 시각화 하기<br>\n",
    "\n",
    "\n",
    "4. **데이터 전 처리:** 머신러닝 모델에 필요한 입력값 형식으로 데이터 처리<br>\n",
    "    4.1. x와 y로 분리<br>\n",
    "    4.2. 데이터 정규화<br>\n",
    "\n",
    "\n",
    "5. **머신러닝 모델 학습:** 분류 모델을 사용하여 학습 수행<br>\n",
    "    5.1. 기본 분류 모델 학습 - 로지스틱 분류기<br>\n",
    "    5.2. 다양한 분류 모델 학습<br>\n",
    "\n",
    "\n",
    "6. **평가 및 예측:** 학습된 모델을 바탕으로 평가 및 예측 수행<br>\n",
    "    6.1. Confusion Matrix<br>\n",
    "    6.2. Precision & Recall<br>\n",
    "    6.3. 테스트 데이터의 예측값 출력<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 출처\n",
    "- https://archive.ics.uci.edu/ml/datasets/SECOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로젝트 개요\n",
    "\n",
    "제조 분야의 디지털 트랜스포메이션이 진행되면서 제조 공정에서 일어나는 수많은 정보가 데이터로 정리되고 있습니다. 제조 공정의 이상을 탐지 분야는 이러한 데이터 바탕으로 구현되는 인공지능 기술로 기존 확률 기반의 예측보다 높은 효율을 내고 있습니다. 이러한 이상 탐지 알고리즘은 불량률을 예측하는 것 뿐만 아니라 어떠한 요소가 불량품을 나오게 하는지 그 원인을 파악하는데 또한 도움을 줄 수 있습니다. 따라서 제조 분야에서의 인공지능을 활용한 이상 탐지는 계속 연구되고 있으며 빠르게 적용되며 그 효율을 보여주고 있습니다.\n",
    "\n",
    "이번 실습에서는 UCI에서 제공하는 SECOM 공정에서 측정된 센서 데이터를 기반으로 한 데이터를 바탕으로 공정 이상을 예측해보는 분류 모델을 구현합니다. 이를 활용하여 센서 데이터가 주어 졌을 때 공정 이상이 생기는지를 예측할 수 있으며, 공정 이상 시 어떠한 센서들이 중요한 역할을 하는지 알아봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 읽기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas를 사용하여 `uci-secom.csv` 데이터를 읽고 dataframe 형태로 저장해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T07:28:25.505639Z",
     "start_time": "2021-07-21T07:28:23.672551Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T07:28:25.790642Z",
     "start_time": "2021-07-21T07:28:25.556650Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# german_credit_data.csv 데이터를 pandas를 사용하여 dataframe 형태로 불러옵니다.\n",
    "data = pd.read_csv('data/uci-secom.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5개의 행을 확인합니다. head()를 사용합니다. head() 안에 숫자를 넣을 수 있습니다. \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataframe의 정보를 요약해서 출력합니다.\n",
    "# info()로 정보를 알 수 있습니다.\n",
    "# shape로 몇 행과 몇 열로 되어있는지 알 수 있습니다. 처음이 행이고 두번째 열입니다.\n",
    "data.info()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 수치형 변수의 데이터 정보를 요약하여 출력합니다.\n",
    "# mean은 평균, std는 표준편차를 나타냅니다. \n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 정제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적으로 데이터 정제에서는 **결측값(missing value)** 또는 **이상치(outlier)**를 처리합니다.\n",
    "\n",
    "**결측값**은 값이 없는 것을 말합니다. NaN, Null이 결측값입니다. \n",
    "\n",
    "**이상치**는 일반적인 범주에서 벗어난 값을 말합니다. 평균 연령을 구할 때 200살과 같이 일반적인 범주에 있지 않는 값을 이상치라고 합니다. \n",
    "\n",
    "머신러닝 모델을 만들 때는 데이터가 중요합니다. 결측값과 이상치는 모델의 성능에 안 좋은 영향을 줄 수 있으므로 처리해서 사용합니다.\n",
    "\n",
    "이번 데이터에서는 수많은 변수(feature)가 존재하기에 각 데이터를 보며 이상치를 처리하기엔 한계가 있습니다.\n",
    "\n",
    "따라서 본 과정에서는 간단하게 결측값에 대해서만 처리를 수행하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드를 수행하여 각 변수별로 결측값이 몇개가 있는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측값 정보를 출력합니다.\n",
    "# isnull()은 결측값이 있는지 True, False로 반환합니다. \n",
    "# data.isnull().sum()로 각 컬럼에서 결측값의 수를 구합니다.\n",
    "# data.isnull().sum().sum()로 전체 결측값의 수를 구할 수 있습니다.\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 데이터를 사용하기 위해서는 결측값을 0으로 대체합니다.\n",
    "\n",
    "결측값이 많지 않다면 fillna(값, inplace=True)를 사용하여 삭제하는 방법도 있습니다.\n",
    "\n",
    "DataFrame.fillna(0, inplace=True)을 하면 결측값을 0으로 바꿉니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측값을 0으로 대체합니다.\n",
    "# np.NaN이 결측값입니다. 이것을 replace을 사용해서 0으로 바꿉니다.\n",
    "data = data.replace(np.NaN, 0)\n",
    "\n",
    "# 결측값 정보를 출력합니다.\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Time'변수의 데이터는 pass/fail을 예측하는데 큰 영향이 없다 생각하여 삭제합니다.\n",
    "# axis=0은 행방향으로 동작합니다. \n",
    "# axis=1은 열 방향으로 동작합니다. \n",
    "# drop() 안에 삭제할 컬럼 이름을 적고 axis =1 로 정합니다.\n",
    "data = data.drop(columns = ['Time'], axis = 1)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data에서 잘 삭제되었는지 확인합니다.\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 데이터 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝을 할 때 숫자만으로는 데이터가 어떤 의미를 갖는지 이해하기 어렵습니다. \n",
    "\n",
    "그래서 데이터를 시각화해서 파악하는 것이 중요합니다. \n",
    "\n",
    "각 변수 분포를 알아보기 위하여 시각화를 수행하겠습니다.\n",
    "\n",
    "센서에 관련된 590개의 변수들은 시각화하기에 너무 양이 많기에 영향력이 크다고 판단되는 `59` 센서에 대해서만 시각화를 진행해 보겠습니다. `59`번 데이터는 머신러닝 모델을 사용했을 때, 높은 중요도로 뽑힌 변수이기에 대표로 출력하였습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. `Pass/Fail` 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 분포를 막대 그래프를 사용하여 출력합니다.\n",
    "# pandas 모듈을 plot()를 사용해서 막대그래프를 그릴 수 있습니다.\n",
    "# value_counts()로 합계를 구합니다.  \n",
    "data['Pass/Fail'].value_counts().plot(kind='bar')\n",
    "\n",
    "# 분포를 도수분포표로 확인합니다.\n",
    "data['Pass/Fail'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. 센서 데이터 시각화 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다수의 feature 데이터에 대해서 한눈에 볼 수 있도록 시각화를 수행할 때는 seaborn의 `pairplot`를 활용하여 해결할 수 있습니다. \n",
    "\n",
    "590개 센서에 대한 출력을 `pairplot`으로 수행하기엔 출력 결과도 보기 힘들뿐더러 출력 시간도 매우 오래 걸립니다.\n",
    "\n",
    "따라서 아래 코드와 같이 3,4,5, Pass/Fail 데이터에 대해서만 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3,4,5,Pass/Fail 컬럼으로 새로운 DataFrame을 만듭니다. 리스트 안에 컬럼 이름을 적습니다. \n",
    "data_test= data[['3','4','5','Pass/Fail']]\n",
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#seaborn의 pairplot()을 사용해서 컬럼끼리 비교할 수 있습니다. \n",
    "sns.pairplot(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vars를 사용해서 특정한 컬럼끼리 비교할 수도 있습니다. \n",
    "sns.pairplot(data_test,height=5, vars=['3','4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. `59`번 센서 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프의 사이즈를 설정합니다.\n",
    "# subplots는 한 번에 여러 그래프를 보여주기 위해서 사용합니다. \n",
    "# subplots()에선 두개의 값을 받을 수 있는데 figure와 axes 값을 받을 수 있습니다. 여기서 변수명은 상관없습니다. 순서가 중요합니다.\n",
    "# fig란 figure로써  전체 subplot을 말합니다. 몇개의 그래프가 있던지 상관없이 그것을 담는 그릇이라고 생각하면 됩니다. 전체 사이즈를 말합니다.\n",
    "# ax는 axe로써 각각의 그래프를 말합니다. \n",
    "# figsize(가로, 세로)로 크기를 정합니다. \n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# seborn 그래프의 스타일을 설정합니다.\n",
    "# style에 white, whitegrid, dark 등을 넣어서 스타일을 바꿀 수 있습니다.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# 59번 데이터의 분포를 출력합니다.\n",
    "# displot로 분포도를 그립니다. \n",
    "# yellow, green와 같은 색깔을 넣습니다. \n",
    "sns.distplot(data['59'], color = 'darkblue')\n",
    "\n",
    "# 그래프의 제목을 설정합니다. \n",
    "plt.title('59 Sensor Measurements', fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 그래프의 사이즈를 설정합니다. 첫번째는 가로, 두번째는 세로의 크기입니다. \n",
    "plt.rcParams['figure.figsize'] = (10, 16)\n",
    "\n",
    "# 3x1 형태로 그래프를 출력하기 위하여 subplot을 설정합니다. \n",
    "# subplot(행, 열, 인덱스)로 그래프의 위치를 정합니다. \n",
    "plt.subplot(3, 1, 1)\n",
    "sns.distplot(data['59'], color = 'darkblue')\n",
    "plt.title('59 Sensor Measurements', fontsize = 20)\n",
    "\n",
    "# 'Pass/Fail' 값이 1인 데이터를 출력합니다.\n",
    "#  data[data['Pass/Fail']==1]를 하면 'Pass/Fail' 값이 1인 행만 사용할 수 있습니다.\n",
    "plt.subplot(3, 1, 2)\n",
    "sns.distplot(data[data['Pass/Fail']==1]['59'], color = 'darkgreen')\n",
    "plt.title('59 Sensor Measurements', fontsize = 20)\n",
    "\n",
    "# 'Pass/Fail' 값이 -1인 데이터를 출력합니다.\n",
    "plt.subplot(3, 1, 3)\n",
    "sns.distplot(data[data['Pass/Fail']==-1]['59'], color = 'red')\n",
    "plt.title('59 Sensor Measurements', fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 그래프의 사이즈를 설정합니다. 첫번째는 가로, 두번째는 세로의 크기입니다.\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "\n",
    "# 위 나누어 출력 했던 그래프를 한번에 출력합니다.\n",
    "sns.distplot(data['59'], color = 'darkblue')\n",
    "sns.distplot(data[data['Pass/Fail']==1]['59'], color = 'darkgreen')\n",
    "sns.distplot(data[data['Pass/Fail']==-1]['59'], color = 'red')\n",
    "\n",
    "# 제목과 폰트크기를 정합니다.\n",
    "plt.title('59 Sensor Measurements', fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 데이터 전 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "공정 이상 예측을 수행하기 위해서 주어진 센서 데이터에 대해서 분류 모델을 사용할 것입니다.\n",
    "\n",
    "분류 모델의 필요한 입력 데이터를 준비 하기위해서 다음과 같은 전 처리를 수행하겠습니다.\n",
    "\n",
    "1. 전체 데이터를 feature 데이터인 `x`와 label 데이터인 `y`로 분리하기\n",
    "2. StandardScaler를 통한 데이터 표준화하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.  `x`와  `y`로 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝의 feature 데이터는 `x`, label 데이터는 `y`에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측해야 할 변수인 `Pass/Fail`를 제거하여 머신러닝 입력값인 x에 저장합니다.\n",
    "# data에는 'Pass/Fail'의 없어집니다. \n",
    "x = data.drop(columns = ['Pass/Fail'], axis = 1)\n",
    "\n",
    "# 예측해야 할 변수 `Pass/Fail`만을 선택하여 numpy 형태로 y에 저장합니다.\n",
    "y = data['Pass/Fail']\n",
    "\n",
    "# ravel은 \"풀다\"로 다차원을 1차원으로 푸는 것을 의미합니다.\n",
    "# 1차원 벡터 형태로 출력하기 위해 ravel 사용합니다. \n",
    "y = y.to_numpy().ravel() \n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타입을 확인합니다. \n",
    "type(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원본 데이터의 수가 많지 않기에 원본 데이터에서 샘플 데이터를 추출하고 노이즈를 추가하여 테스트 데이터를 생성하였습니다.\n",
    "\n",
    "`data` 폴더 내의 `uci-secom-test.csv`에 590개의 센서 데이터와 `Pass/Fail`저장되어 있기에 해당 데이터를 읽어와 `x_test, y_test` 데이터로 분리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data 폴더 내의 uci-secom-test.csv를 DataFrame으로 읽고 x_test, y_test로 분리합니다. \n",
    "data_test = pd.read_csv(\"data/uci-secom-test.csv\")\n",
    "x_test = data_test.drop(columns = ['Pass/Fail'], axis = 1)\n",
    "y_test = data_test['Pass/Fail'].to_numpy().ravel() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. 데이터 표준화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 변수 마다의 스케일 차이를 맞추기 위하여 표준화를 수행합니다. \n",
    "\n",
    "표준화는 서로 다른 피처의 크기를 통일하기 위해서 크기를 변환해주는 개념입니다.\n",
    "\n",
    "데이터의 피처 각각이 평균이 0이고 분산이 1인 가우시안 정규 분포를 형태와 가까워지도록 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 정규화를 위해서 StandardScaler 불러옵니다.\n",
    "sc = StandardScaler()\n",
    "\n",
    "# x_train에 있는 데이터에 맞춰 정규화를 진행합니다. \n",
    "x_train = sc.fit_transform(x)\n",
    "x_test = sc.transform(x_test)\n",
    "y_train = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#mean()으로 평균을 구하고 var()로 분산을 구합니다. \n",
    "#e는 소수부의 크기를 알려주는 자리입니다. 여기서는 엄청 작은 값으로 0으로 생각하면 됩니다. \n",
    "x_train_sc = pd.DataFrame(data=x_train)\n",
    "print(\"평균\")\n",
    "print(x_train_sc.mean())\n",
    "print(\"분산\")\n",
    "print(x_train_sc.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 머신러닝 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전 처리된 데이터를 바탕으로 분류 모델을 학습을 수행하고 학습 결과를 출력 해봅니다.\n",
    "\n",
    "먼저 기본적인 분류 모델인 **로지스틱 분류기(logistic regression classifier)**를 사용하여 학습을 수행하고, 다양한 모델들을 살펴봅시다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 로지스틱 회귀\n",
    "로지스틱 회귀는 선형 회귀 방식을 분류에 적용한 알고리즘입니다. \n",
    "\n",
    "로지스틱 회귀는 회귀라는 말이 들어갔지만 분류에 사용됩니다. \n",
    "\n",
    "로지스틱 회귀가 선형 회귀와 다른 점은 학습을 통해 선형 함수의 회귀 최적선을 찾는 것이 아닙니다.\n",
    "\n",
    "시그모이드 함수 최적선을 찾고 이 시그모이드 함수의 반환 값을 확률로 간주해 확률에 따라 분류를 결정한다는 점입니다. \n",
    "\n",
    "확률에 따라서 분류를 결정합니다.\n",
    "\n",
    "로지스틱 회귀는 주로 이진(0과 1) 분류에 사용됩니다. 로지스틱 회귀에서 예측 값은 예측 확률의 의미합니다.\n",
    "\n",
    "예측 값 즉, 예측 확률이 0.5이상이면 1로, 그렇지 않으면 0으로 예측합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/1-1.png\" width=\"30%\" height=\"30%\" title=\"로지\" alt=\"로지\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. 기본 분류 모델 학습 - 로지스틱 분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 로지스틱 분류기 모델 class를 가져 옵니다.\n",
    "# max_iter는 로지스틱 알고리즘의 반복 횟수를 정하는 파라미터로 본 실습에서는 default 값으로는 모자르기에 아래와 같이 설정합니다.\n",
    "model = LogisticRegression(max_iter=5000)\n",
    "\n",
    "# 데이터를 학습시킬 때는 fit 함수를 사용합니다. \n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# score 함수를 사용하여 모델의 성능을 확인합니다. \n",
    "print(model.score(x_train, y_train))\n",
    "print(model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression의 중요도를 계산합니다.\n",
    "# 가중치 값들의 크기로 판단하기에 .coef_로 해당 값들을 불러옵니다.\n",
    "abs_coef = np.abs(model.coef_).ravel()\n",
    "abs_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar 형태 그래프로 Logistic Regression의 feature 별 중요도를 상위 20개 출력합니다.\n",
    "# 상위 20개의 feature 정보를 출력하기 위하여 sorting을 수행하고 해당 feature 번호를 LR_imort_x에 저장합니다.\n",
    "LR_import_x = [str(i[0]) for i in sorted(enumerate(abs_coef), key=lambda x:x[1], reverse=True)]\n",
    "\n",
    "plt.bar(LR_import_x[:20], sorted(abs_coef, reverse=True)[:20])\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Weight absolute values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**퀴즈1. 위 학습된 LogisticRegression 모델에서 Weight absolute value가 30번째인 값을 구하세요.**\n",
    "\n",
    "첫 번째 Weight absolute value의 값은 `sorted(abs_coef, reverse=True)[0]`으로 구할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(abs_coef, reverse=True) 을 활용하면 쉽게 구할 수 있습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치형 값으로 입력합니다. (배열 형태는 오답 처리됩니다.)\n",
    "quiz_1 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. 다양한 분류 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost 설치가 잘 안되면 Anaconda Powershell Prompt(anaconda3)에서 해봅니다.\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "\n",
    "#여러 모델을 append해서 추가합니다. \n",
    "models = []\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))  # LDA 모델\n",
    "models.append(('KNN', KNeighborsClassifier()))  # KNN 모델\n",
    "models.append(('CART', DecisionTreeClassifier()))  # 의사결정트리 모델\n",
    "models.append(('NB', GaussianNB()))  # 가우시안 나이브 베이즈 모델\n",
    "models.append(('RF', RandomForestClassifier()))  # 랜덤포레스트 모델\n",
    "models.append(('SVM', SVC(gamma='auto')))  # SVM 모델\n",
    "models.append(('XGB', XGBClassifier()))  # XGB 모델\n",
    "\n",
    "for name, model in models:\n",
    "    # fit으로 학습을 합니다. \n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    # %s와 %f는 문자열 포맷팅으로 %s는 문자열, %f는 숫자형 데이터를 말합니다. \n",
    "    # 문자열 포맷팅 값은 괄호()안의 값과 대응됩니다.\n",
    "    # score 함수를 사용하여 모델의 성능을 확인합니다.\n",
    "    msg = \"%s - train_score : %f, test score : %f\" % (name, model.score(x_train, y_train), model.score(x_test, y_test))\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb 모델에서 변수 중요도를 출력합니다.\n",
    "# xgboost 모듈의 plot_importance는 피처 중요도를 시각화할 때 사용합니다. \n",
    "# models[-1][1]는 models 리스트에서 맨 마지막 요소(이것도 리스트)에서 두번째 요소를 말합니다. \n",
    "# importance_type는 중요도가 어떻게 계산되는지 정합니다. \n",
    "# weight는 나온 횟수를 말합니다. gain은 평균적인 이득을 말합니다. cover는 coverage의 평균입니다. \n",
    "\n",
    "xgb.plot_importance(models[-1][1], height = 1, grid = True, importance_type = 'total_gain', show_values = False, max_num_features = 20)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 15)\n",
    "plt.xlabel('The F-Score for each features')\n",
    "plt.ylabel('Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 평가 및 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 과정에서 학습 데이터와 테스트 데이터에 대해서 accuracy 계산하여 평가하였습니다.\n",
    "\n",
    "accuracy의 경우 아래 식에서 알 수 있듯이 얼마나 정확히 예측했는가를 정량적으로 나타냅니다.\n",
    "\n",
    "$Accuracy = \\frac{Number \\;of \\;correct \\;predictions}{Total \\; number \\;of \\;predictions} $\n",
    "\n",
    "Accuracy 값이 높으면 좋은 성능을 낸다고도 할 수 있지만 이번 실습인 공정 이상 예측에서는 recall 값 또한 살펴봐야 합니다.\n",
    "\n",
    "오차행렬(Confusion Matrix)은 이진 분류의 예측 오류가 얼마인지와 더불어 어떠한 유형의 예측 오류가 발생하고 있는지를 함께 나타내는 지표입니다. \n",
    "\n",
    "+ TN : Negative(0)로 예측했고, 실제로도 True인 경우 - 실제는 Negative\n",
    "+ FP : Positive(1)로 예측했지만 실제는 False인 경우 - 실제는 Negative\n",
    "+ FN : Negative(0)로 예측했고, 실제는 False인 경우 - 실제는 Positive\n",
    "+ TP : Positive(1)로 예측했고, 실제로도 True인 경우 - 실제는 Positive\n",
    "\n",
    "공정 이상 예측에서 중요한 것은 이상 없음을 정확히 예측하는 것 보단 이상 있음을 정확히 예측하는 것입니다. \n",
    "\n",
    "recall 방식은 `예측한 이상 있음` 대비 `실제 이상 있음`의 비율을 나타내기에 accuracy에서 놓칠 수 있는 결과 해석을 보충합니다.\n",
    "\n",
    "정밀도(Precision)는 예측을 Positve로 한 대상 중에 예측과 실제 값이 Positive로 일치한 데이터의 비율을 뜻합니다. 정밀도는 FP가 낮아야 합니다. \n",
    "+ TP / (FP + TP)\n",
    "\n",
    "재현율(recall)은 실제 값이 Positive인 대상 중에 예측과 실제 값이 Positive로 일치한 데이터의 비율을 말합니다. 재현율은 FN이 낮아야 합니다.\n",
    "+ TP / (FN + TP)\n",
    "\n",
    "\n",
    "이번 파트에서는 recall 방식을 포함한 또 다른 대표적인 평가 방법에 대해서 알아보고 주어진 데이터에 대해서 예측하는 것을 수행해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존 score에서 볼 수 있었던 결과는 accuracy 기반의 결과였습니다. confusion matrix를 출력하여 각 class 별로 예측한 결과에 대해서 자세히 알아봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns \n",
    "\n",
    "# LinearDiscriminantAnalysis 모델의 confusion matrix를 사용하기 위하여 학습용 데이터의 예측값을 저장합니다.\n",
    "# models[0]는 LDA\n",
    "model_predition_train = models[0][1].predict(x_train)\n",
    "\n",
    "# sklearn에서 제공하는 confusion_matrix를 사용합니다.\n",
    "cm_train = confusion_matrix(y_train, model_predition_train)\n",
    "\n",
    "# 출력 파트 - seaborn의 heatmap을 사용\n",
    "plt.rcParams['figure.figsize'] = (5, 5)\n",
    "sns.set(style = 'dark', font_scale = 1.4)\n",
    "\n",
    "# annot은 annotate each cell with numeric value로 셀에 숫자값을 표시하는지 정하는 것입니다. \n",
    "# cmap으로 색깔을 지정할 수 있습니다. cmap='RdYlGn_r' cmap=\"YlGnBu\"\n",
    "ax = sns.heatmap(cm_train, annot=True)\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Real Data')\n",
    "ax.set_xticklabels((-1,1))\n",
    "ax.set_yticklabels((-1,1))\n",
    "plt.show()\n",
    "cm_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 confusion matrix에서 x 축은 실제 데이터의 label을 의미하고 y 축은 예측한 데이터의 label을 의미합니다.\n",
    "\n",
    "- **0,0 의 값:** `이상 없음(Pass)` 이라고 예측했을 때, 실제 데이터가 `이상 없음(Pass)`인 경우의 개수\n",
    "- **0,1 의 값:** `이상 있음(Fail)` 이라고 예측했을 때, 실제 데이터가 `이상 없음(Pass)`인 경우의 개수\n",
    "- **1,0 의 값:** `이상 없음(Pass)` 이라고 예측했을 때, 실제 데이터가 `이상 있음(Fail)`인 경우의 개수\n",
    "- **1,1 의 값:** `이상 있음(Fail)` 이라고 에측했을 때, 실제 데이터가 `이상 있음(Fail)`인 경우의 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**퀴즈2. LDA 모델에서 평가용 데이터(`x_test, y_test`)의 confusion matrix를 구하세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinearDiscriminantAnalysis의 x_test에 대한 예측값을 구하고 confusion_matrix() 를 사용하면 confusion matrix를 구할 수 있습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix() 결과값을 저장합니다. \n",
    "quiz_2 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Precision & Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분류 모델의 또 다른 성능 지표로 Precsion과 Recall를 구하여 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# sklearn에서 제공하는 recall_score, precision_score를 사용하여 recall과 precision 결과물을 출력합니다.\n",
    "print(\"Recall score: {}\".format(recall_score(y_test, models[0][1].predict(x_test))))\n",
    "print(\"Precision score: {}\".format(precision_score(y_test, models[0][1].predict(x_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. 테스트 데이터의 예측값 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 데이터를 하나씩 입력하여 그 결과를 출력해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 0번부터 9번까지 10개를 출력해보겠습니다.\n",
    "for i in range(10): \n",
    "    \n",
    "    # LDA 모델을 사용하였습니다.\n",
    "    # reshape()에서 -1이 들어간 곳은 가변적으로 바꿉니다. 예를 들어 12개의 원소가 있고 reshape(-1,2)를 하면 열 2개를 맞추기 위해서 행을 6개로 바꿉니다. \n",
    "    prediction = models[0][1].predict(x_test[i].reshape(1,-1))\n",
    "    \n",
    "    #문자열 포맷팅의 방법입니다. {}가 괄호()안의 값에 각각 대응됩니다. \n",
    "    print(\"{} 번째 테스트 데이터의 예측 결과: {}, 실제 데이터: {}\".format(i, prediction[0], y_test[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제출하기\n",
    "\n",
    "퀴즈 1번, 2번까지 수행 후, 아래 코드를 실행하면 `quize_1, quize_2` 변수가 저장된 `submission.pickle` 파일을 제작하여 채점을 받을 수 있습니다.\n",
    "\n",
    "**아래 코드를 수정하면 채점이 불가능 합니다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "d = {'quiz_1': quiz_1, 'quiz_2': quiz_2}\n",
    "\n",
    "with open('submission.pickle', 'wb') as f:\n",
    "    pickle.dump(d, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 채점을 수행하기 위하여 로그인\n",
    "import sys\n",
    "sys.path.append('vendor')\n",
    "from elice_challenge import check_score, upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 파일 업로드\n",
    "await upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 채점 수행\n",
    "await check_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 챌린지\n",
    "\n",
    "이번 프로젝트에서 사용한 모델은 학습용 데이터에 대한 **accuracy**는 좋은 성능을 보여주었지만, 평가용 데이터에서 **accuracy, recall** 지표는 좋은 성능을 보여주지 못 하였습니다. 다양한 방식을 사용하여 평가용 데이터에서의 **accuracy, recall**을 높일 수 있는 방법을 찾아봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:rgb(120, 120, 120)\">본 학습 자료를 포함한 사이트 내 모든 자료의 저작권은 엘리스에 있으며 외부로의 무단 복제, 배포 및 전송을 불허합니다.\n",
    "\n",
    "Copyright @ elice all rights reserved</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
