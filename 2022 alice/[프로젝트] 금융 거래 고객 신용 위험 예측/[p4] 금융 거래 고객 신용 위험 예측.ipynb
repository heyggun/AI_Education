{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Project 4] 금융 거래 고객 신용 위험 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로젝트 목표\n",
    "- 금융 거래 데이터 분석을 통하여 고객 신용 위험을 예측하는 분류 모델 수행\n",
    "- 고객 신용 위험에 영향을 미치는 특성 데이터들에 대한 데이터 분석 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로젝트 목차\n",
    "1. **데이터 읽기:** 금융 데이터를 불러오고 Dataframe 구조를 확인\n",
    "    \n",
    "\n",
    "2. **데이터 정제:** 비어 있는 데이터 또는 쓸모 없는 데이터를 삭제\n",
    "\n",
    "\n",
    "3. **데이터 시각화:** 변수 시각화를 통하여 분포 파악<br>\n",
    "    3.1. Age 시각화<br>\n",
    "    3.2. Sex 시각화<br>\n",
    "    3.3. Job 시각화<br>\n",
    "    3.4. Housing 시각화<br>\n",
    "    3.5. Saving accounts 시각화<br>\n",
    "    3.6. Checking account 시각화<br>\n",
    "    3.7. Credit amount 시각화<br>\n",
    "    3.8. Duration 시각화<br>\n",
    "    3.9. Purpose 시각화<br>\n",
    "    3.10. Risk 시각화<br>\n",
    "    \n",
    "\n",
    "4. **데이터 전 처리:** 머신러닝 모델에 필요한 입력값 형식으로 데이터 처리<br>\n",
    "    4.1. Object 자료형 -> 수치 자료형 변환 - Dummy<br>\n",
    "    4.2. 학습, 테스트 데이터 분리<br>\n",
    "    \n",
    "\n",
    "5. **머신러닝 모델 학습:** 분류 모델을 사용하여 학습 수행<br>\n",
    "    5.1. 기본 분류 모델 학습 - 의사결정나무<br>\n",
    "    5.2. 다양한 분류 모델 학습<br>\n",
    "    5.3. 모델 튜닝 및 K-fold 교차 검증<br>\n",
    "\n",
    "\n",
    "6. **평가 및 예측:** 학습된 모델을 바탕으로 평가 및 예측 수행<br>\n",
    "    6.1. Confusion Matrix<br>\n",
    "    6.2. Precision & Recall<br>\n",
    "    6.3. 테스트 데이터의 예측값 출력<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 출처\n",
    "-  https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로젝트 개요\n",
    "\n",
    "금융 거래 데이터는 해당 데이터에 속한 사람들의 소비 패턴을 판단할 수 있고 나아가 생활 패턴까지 유추할 수 있게 합니다. 이러한 정보는 마케터나 금융기관에서 상품을 적절하게 추천할 수 있도록 도움을 줄 수 있습니다. 특히나 고객의 신용 위험 정도는 금융 상품을 추천하거나, 금융 활동을 제한하는데 있어서 중요한 정보로 사용될 수 있을 것입니다.\n",
    "\n",
    "이번 프로젝트에서는 독일 금융 거래 고객 데이터를 바탕으로 금융 고객의 신용 위험을 예측해보는 분류 모델을 구현합니다. 데이터 분석 및 분류 모델을 바탕으로 새로운 고객의 데이터를 받았을 때, 신용 위험 여부를 예측할 수 있으며, 어떠한 특성 데이터가 위험 여부를 예측하는데 큰 영향을 미쳤는지 또한 알 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 읽기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas를 사용하여 `german_credit_data.csv` 데이터를 읽고 dataframe 형태로 저장해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# german_credit_data.csv 데이터를 pandas를 사용하여 dataframe 형태로 불러옵니다.\n",
    "df_origin = pd.read_csv(\"./data/german_credit_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5개의 데이터 샘플을 출력합니다.\n",
    "df_origin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataframe의 정보를 요약해서 출력합니다.\n",
    "df_origin.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치형 변수의 데이터 정보를 요약하여 출력합니다.\n",
    "df_origin.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 정제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 정제에서는 **결측값(missing value)** 또는 **이상치(outlier)**를 처리합니다.\n",
    "\n",
    "이번 파트에서는 간단한 결측값 처리로 대체 방식을 수행해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드를 수행하여 각 변수별로 결측값이 몇개가 있는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 결측값 정보를 출력합니다.\n",
    "df_origin.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1000개 뿐이 없는 데이터이기에 일반적으로 사용하는 결측값 삭제 방법을 사용하지 않고 결측값을 아래와 같이 대체하여 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정제 작업이 수행될 dataframe 을 df_claen으로 정의합니다. \n",
    "df_clean = df_origin\n",
    "\n",
    "# 'Saving accounts' ,'Checking account' 변수에 있는 결측값을 `Others`로 대체합니다.\n",
    "df_clean['Saving accounts'] = df_origin['Saving accounts'].fillna('Others')\n",
    "df_clean['Checking account'] = df_origin['Checking account'].fillna('Others')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측값 정보를 출력합니다.\n",
    "df_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 데이터 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 변수 분포를 알아보기 위하여 시각화를 수행하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. `Age` 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seaborn을 사용하면 아래와 같이 시각화 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프의 사이즈를 조절합니다.\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "# seaborn의 countplot 함수를 사용하여 출력합니다.\n",
    "sns.set(style='darkgrid')\n",
    "ax = sns.countplot(x='Age', data=df_clean, palette=\"Set2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_clean['Age'], hist=False, label='ALL')\n",
    "sns.distplot(df_clean[df_clean['Risk']=='good']['Age'], hist=False, label='good')\n",
    "sns.distplot(df_clean[df_clean['Risk']=='bad']['Age'], hist=False, label='bad')\n",
    "\n",
    "plt.legend(title='Risk')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. `Sex` 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분포를 막대 그래프를 사용하여 출력합니다.\n",
    "df_clean['Sex'].value_counts().plot(kind='bar')\n",
    "\n",
    "# 분포를 도수분포표로 확인합니다.\n",
    "df_clean['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplot(columns):\n",
    "    df_multi = pd.DataFrame({'ALL': df_clean[columns].value_counts().sort_index().values,\n",
    "                          'good': df_clean[df_clean['Risk']=='good'][columns].value_counts().sort_index().values,\n",
    "                          'bad': df_clean[df_clean['Risk']=='bad'][columns].value_counts().sort_index().values\n",
    "                          }, index=df_clean[columns].value_counts().sort_index().index)\n",
    "\n",
    "    df_multi.plot(kind='bar')\n",
    "    plt.legend(title='Risk')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplot('Sex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. `Job` 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분포를 막대 그래프를 사용하여 출력합니다.\n",
    "df_clean['Job'].value_counts().plot(kind='bar')\n",
    "\n",
    "# 분포를 도수분포표로 확인합니다.\n",
    "df_clean['Job'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplot('Job')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. `Housing ` 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분포를 막대 그래프를 사용하여 출력합니다.\n",
    "df_clean['Housing'].value_counts().plot(kind='bar')\n",
    "\n",
    "# 분포를 도수분포표로 확인합니다.\n",
    "df_clean['Housing'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplot('Housing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. `Saving accounts ` 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 분포를 막대 그래프를 사용하여 출력합니다.\n",
    "df_clean['Saving accounts'].value_counts().plot(kind='bar')\n",
    "\n",
    "# 분포를 막대 그래프를 사용하여 출력합니다.\n",
    "df_clean['Saving accounts'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multiplot('Saving accounts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6. `Checking account ` 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분포를 막대 그래프를 사용하여 출력합니다.\n",
    "df_clean['Checking account'].value_counts().plot(kind='bar')\n",
    "\n",
    "# 분포를 막대 그래프를 사용하여 출력합니다.\n",
    "df_clean['Checking account'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplot('Checking account')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**퀴즈1. `df_clean` 데이터에서 `Risk`가 `bad`이고, `Checking account`와 `Saving accounts`가 모두 `little`인 샘플 수를 구하세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame에서 복수의 조건을 사용 시, DataFrame(A & B & C)을 활용해봅시다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int형으로 결과값을 저장합니다. \n",
    "quiz_1 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7. `Credit amount ` 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치형 데이터는 boxplot으로 분포를 출력합니다.\n",
    "plt.boxplot(df_clean['Credit amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='Risk', y='Credit amount', data=df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8. `Duration ` 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치형 데이터는 boxplot으로 분포를 출력합니다.\n",
    "plt.boxplot(df_clean['Duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='Risk', y='Duration', data=df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9. `Purpose` 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분포를 막대 그래프를 사용하여 출력합니다.\n",
    "df_clean['Purpose'].value_counts().plot(kind='bar')\n",
    "\n",
    "# 분포를 막대 그래프를 사용하여 출력합니다.\n",
    "df_clean['Purpose'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplot('Purpose')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.10. `Risk` 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분포를 막대 그래프를 사용하여 출력합니다.\n",
    "df_clean['Risk'].value_counts().plot(kind='bar')\n",
    "\n",
    "# 분포를 막대 그래프를 사용하여 출력합니다.\n",
    "df_clean['Risk'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 데이터 전 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신용 예측을 수행하기 위해서 주어진 금융 거래 데이터에 대해서 분류 모델을 사용할 것입니다.\n",
    "\n",
    "분류 모델의 필요한 입력 데이터를 준비 하기위해서 다음과 같은 전처리를 수행하겠습니다.\n",
    "\n",
    "1. Object 자료형 -> 숫자 자료형 변환하기\n",
    "2. 학습 데이터와 테스트 데이터로 나누기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Object 자료형 -> 수치 자료형 변환 - Dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적인 머신러닝 모델에서는 수치 자료형만을 입력값으로 사용합니다. 따라서 수치 자료형만을 사용하여 입력값으로 사용할 수 있지만, 신용 예측을 위한 데이터에 존재하는 `Housing`, `Sex`. `Job`과 같은 중요한 정보일 수 잇는 object 자료형을 사용할 수가 없습니다.\n",
    "\n",
    "그렇기에 이러한 object 자료형을 수치 자료형으로 변환하는 dummy 방식을 사용하여 다양한 데이터를 수치형 입력으로 사용해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2개의 카테고리를 갖는 데이터는 replace를 사용하여 0,1로 변환 합니다.\n",
    "df_clean = df_clean.replace(['good','bad'],[0,1])\n",
    "\n",
    "# object 자료형 데이터의 변수를 정리합니다.\n",
    "cat_features = ['Sex','Housing', 'Saving accounts', 'Checking account','Purpose']\n",
    "# 수치 자료형 데이터의 변수를 정리합니다.\n",
    "num_features=['Age', 'Job', 'Credit amount', 'Duration','Risk']\n",
    "\n",
    "# 더미를 기법을 사용하여 변환합니다.\n",
    "for variable in cat_features:\n",
    "    # pandas의 더미 방식을 사용하여 object 자료형 데이터를 변환한 dataframe을 생성합니다.\n",
    "    dummies = pd.get_dummies(df_clean[cat_features])\n",
    "    # 기존 수치형 데이터에 더미로 새로 생성된 데이터를 추가합니다.\n",
    "    df1= pd.concat([df_clean[num_features], dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측해야 할 변수인 `Risk`를 제거하여 머신러닝 입력값인 x에 저장합니다.\n",
    "x = df1.drop(columns = ['Risk']).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측해야 할 변수 `Risk`만을 선택하여 numpy 형태로 y에 저장합니다.\n",
    "y = df_clean['Risk']\n",
    "y = y.to_numpy().ravel() # 1 차원 벡터 형태로 출력하기 위해 ravel 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. 학습, 테스트 데이터 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝의 성능을 평가 하기 위해서는 전체 데이터를 학습에 사용하지 않고 학습용 데이터와 테스트용 데이터를 나누어 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# sklearn에서 제공하는 train_test_split을 사용하여 손 쉽게 분리 할 수 있습니다.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 머신러닝 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전 처리된 데이터를 바탕으로 분류 모델을 학습을 수행하고 학습 결과를 출력 해봅니다.\n",
    "\n",
    "먼저 기본적인 분류 모델인 **의사결정나무**를 사용하여 학습을 수행하고, 다양한 모델들을 살펴봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. 기본 분류 모델 학습 - 의사결정나무"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 의사결정 모델 class를 가져 옵니다.\n",
    "# max_iter는 로지스틱 알고리즘의 반복 횟수를 조정하는 파라미터로 본 실습에서는 default 값으로는 모자르기에 아래와 같이 설정함\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# fit 함수를 사용하여 데이터를 학습합니다.\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# score 함수를 사용하여 모델의 성능을 출력합니다.\n",
    "print(model.score(x_train, y_train))\n",
    "print(model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. 다양한 분류 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로지스틱 분류기 모델 이외의 다양한 분류 알고리즘을 사용하고 그 성능을 비교하여 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(max_iter =5000))) # 로지스틱 분류기 \n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))  # LDA 모델\n",
    "models.append(('KNN', KNeighborsClassifier()))  # KNN 모델\n",
    "models.append(('NB', GaussianNB()))  # 가우시안 나이브 베이즈 모델\n",
    "models.append(('RF', RandomForestClassifier()))  # 랜덤포레스트 모델\n",
    "models.append(('SVM', SVC(gamma='auto')))  # SVM 모델\n",
    "models.append(('XGB', XGBClassifier()))  # XGB 모델\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(x_train, y_train)\n",
    "    msg = \"%s - train_score : %f, test score : %f\" % (name, model.score(x_train, y_train), model.score(x_test, y_test))\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# xgb 모델에서 변수 중요도를 출력합니다.\n",
    "max_num_features = 20\n",
    "ax = xgb.plot_importance(models[-1][1], height = 1, grid = True, importance_type = 'gain', show_values = False, max_num_features = max_num_features)\n",
    "\n",
    "ytick = ax.get_yticklabels()\n",
    "feature_importance = []\n",
    "for i in range(max_num_features):\n",
    "    feature_importance.append(df1.drop(columns=['Risk']).columns[int(ytick[i].get_text().split('f')[1])])\n",
    "\n",
    "ax.set_yticklabels(feature_importance)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 15)\n",
    "plt.xlabel('The F-Score for each features')\n",
    "plt.ylabel('Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. 모델 튜닝 및 K-fold 교차 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝 모델들은 데이터의 특성에 잘 맞도록 다양한 파라미터를 조절하여 성능을 높일 수 있습니다. 이러한 과정을 모델 튜닝이라 하며 본 과정에서는 GridSearchCV를 사용하여 구현해보겠습니다. 추가로 k-fold 방식 또한 사용하여 학습 과정에서 생길 수 있는 과적합을 예방해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 성능 비교에 필요한 모델 파라미터들을 정의합니다.\n",
    "parameters = {'criterion': ['gini','entropy'], \n",
    "              'max_depth': [3, 4, 5, 6],\n",
    "              'max_features': ['auto', 'sqrt', 'log2']}\n",
    "\n",
    "# 5개의 fold를 구성합니다.\n",
    "cv = KFold(n_splits=5)\n",
    "# 의사결정트리 모델을 튜닝하기 위하여 선언합니다.\n",
    "DT = DecisionTreeClassifier()\n",
    "\n",
    "# 모델 튜닝을 우해서 GridSearchCV를 사용합니다.\n",
    "DT_CV = GridSearchCV(DT, parameters, scoring = 'accuracy', cv = cv, n_jobs= -1)\n",
    "# 학습을 수행합니다.\n",
    "DT_CV.fit(x_train, y_train)\n",
    "\n",
    "# 결과를 출력합니다.\n",
    "print(DT_CV.score(x_train, y_train))\n",
    "print(DT_CV.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 가장 성능이 좋았던 파라미터를 출력합니다.\n",
    "DT_CV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 성능이 좋았던 파라미터로 수행한 모델을 저장합니다.\n",
    "best_DT_CV = DT_CV.best_estimator_\n",
    "\n",
    "# 가장 좋은 성능을 보여준 모델의 결과를 출력합니다.\n",
    "best_DT_CV.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 평가 및 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 과정에서 학습 데이터와 테스트 데이터에 대해서 accuracy 계산하여 평가하였습니다.\n",
    "\n",
    "accuracy의 경우 아래 식에서 알 수 있듯이 얼마나 정확히 예측했는가를 정량적으로 나타냅니다.\n",
    "\n",
    "$Accuracy = \\frac{Number \\;of \\;correct \\;predictions}{Total \\; number \\;of \\;predictions} $\n",
    "\n",
    "Accuracy 값이 높으면 좋은 성능을 낸다고도 할 수 있지만 이번 실습인 신용 위험 예측에서는 recall 값 또한 살펴봐야 합니다.\n",
    "\n",
    "신용 위험 예측에서 중요한 것은 위험 없음을 정확히 예측하는 것 보단 위험 있음을 정확히 예측하는 것입니다. \n",
    "\n",
    "recall 방식은 `예측한 위험 있음` 대비 `실제 위험 있음`의 비율을 나타내기에 accuracy에서 놓칠 수 있는 결과 해석을 보충합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존 score에서 볼 수 있었던 결과는 accuracy 기반의 결과였습니다. confusion matrix를 출력하여 각 class 별로 예측한 결과에 대해서 자세히 알아봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# xgb 모델의 confusion matrix를 사용하기 위하여 테스트 데이터의 예측값을 저장합니다.\n",
    "model_predition = models[-1][1].predict(x_test)\n",
    "\n",
    "# sklearn에서 제공하는 confusion_matrix를 사용합니다.\n",
    "cm = confusion_matrix(y_test, model_predition)\n",
    "\n",
    "# 출력 파트 - seaborn의 heatmap을 사용\n",
    "plt.rcParams['figure.figsize'] = (5, 5)\n",
    "sns.set(style = 'dark', font_scale = 1.4)\n",
    "ax = sns.heatmap(cm, annot=True)\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Real Data')\n",
    "plt.show()\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 confusion matrix에서 x 축은 실제 데이터의 label을 의미하고 y 축은 예측한 데이터의 label을 의미합니다.\n",
    "\n",
    "- **0,0 의 값:** `위험 없음(Pass)` 이라고 예측했을 때, 실제 데이터가 `위험 없음(Pass)`인 경우의 개수\n",
    "- **0,1 의 값:** `위험 있음(Fail)` 이라고 예측했을 때, 실제 데이터가 `위험 없음(Pass)`인 경우의 개수\n",
    "- **1,0 의 값:** `위험 없음(Pass)` 이라고 예측했을 때, 실제 데이터가 `위험 있음(Fail)`인 경우의 개수\n",
    "- **1,1 의 값:** `위험 있음(Fail)` 이라고 에측했을 때, 실제 데이터가 `위험 있음(Fail)`인 경우의 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**퀴즈2. `best_DT_CV` 모델에서 평가용 데이터(`x_test, y_test`)의 confusion matrix를 구하세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_DT_CV의 x_test에 대한 예측값을 구하고 confusion_matrix() 를 사용하면 confusion matrix를 구할 수 있습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix() 결과값을 저장합니다. \n",
    "quiz_2 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Precision & Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분류 모델의 또 다른 성능 지표로 Precsion과 Recall를 구하여 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# sklearn에서 제공하는 recall_score, precision_score를 사용하여 recall과 precision 결과물을 출력합니다.\n",
    "print(\"Recall score: {}\".format(recall_score(y_test, model_predition)))\n",
    "print(\"Precision score: {}\".format(precision_score(y_test, model_predition)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. 테스트 데이터의 예측값 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 데이터를 하나씩 입력하여 그 결과를 출력해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 0번부터 9번까지 10개를 출력해보겠습니다.\n",
    "for i in range(10): \n",
    "    \n",
    "    # XGB 모델을 사용하였습니다.\n",
    "    prediction = models[-1][1].predict(x_test[i].reshape(1,-1))\n",
    "    print(\"{} 번째 테스트 데이터의 예측 결과: {}, 실제 데이터: {}\".format(i, prediction[0], y_test[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제출하기\n",
    "\n",
    "퀴즈 1번, 2번까지 수행 후, 아래 코드를 실행하면 `quize_1, quize_2` 변수가 저장된 `submission.pickle` 파일을 제작하여 채점을 받을 수 있습니다.\n",
    "\n",
    "**아래 코드를 수정하면 채점이 불가능 합니다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "d = {'quiz_1': quiz_1, 'quiz_2': quiz_2}\n",
    "\n",
    "with open('submission.pickle', 'wb') as f:\n",
    "    pickle.dump(d, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 채점을 수행하기 위하여 로그인\n",
    "import sys\n",
    "sys.path.append('vendor')\n",
    "from elice_challenge import check_score, upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 파일 업로드\n",
    "await upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 채점 수행\n",
    "await check_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 챌린지\n",
    "\n",
    "이번 프로젝트에서 사용한 모델은 학습용 데이터에 대한 **accuracy**는 좋은 성능을 보여주었지만, 평가용 데이터에서 **precision, recall** 지표는 좋은 성능을 보여주지 못 하였습니다. 다양한 방식을 사용하여 평가용 데이터에서의 **precision, recall**을 높일 수 있는 방법을 찾아봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:rgb(120, 120, 120)\">본 학습 자료를 포함한 사이트 내 모든 자료의 저작권은 엘리스에 있으며 외부로의 무단 복제, 배포 및 전송을 불허합니다.\n",
    "\n",
    "Copyright @ elice all rights reserved</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
