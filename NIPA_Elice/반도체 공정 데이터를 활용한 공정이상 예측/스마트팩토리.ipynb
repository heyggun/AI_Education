{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd076927",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\envs\\vmconda\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\PC\\anaconda3\\envs\\vmconda\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "C:\\Users\\PC\\anaconda3\\envs\\vmconda\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a33f481354b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sys\n",
    "from tqdm import trange\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# to avoid warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, average_precision_score\n",
    "\n",
    "from elice_utils import EliceUtils\n",
    "elice_utils = EliceUtils()\n",
    "\n",
    "def preprocess():\n",
    "\n",
    "    print(\"데이터 읽는 중...\")\n",
    "    data = pd.read_csv('data/uci-secom.csv')\n",
    "    \n",
    "    print(\"읽어 온 데이터를 출력합니다.\")\n",
    "    print(data)\n",
    "    \n",
    "    #print(data.isnull().sum())\n",
    "    #print(\"결측 데이터 값을 처리합니다.\")\n",
    "    data = data.replace(np.NaN, 0)\n",
    "    #print(data.isnull().sum())\n",
    "    \n",
    "    # 쓸모없는 데이터 지우기\n",
    "    data = data.drop(columns = ['Time'], axis = 1)\n",
    "    \n",
    "    # 타겟 데이터 분리\n",
    "    x = data.iloc[:,:590]\n",
    "    y = data.iloc[:, 590]\n",
    "\n",
    "    print(\"\\n학습용 데이터와 테스트용 데이터로 분리 합니다.\")\n",
    "\n",
    "    # Under sampling 수행\n",
    "    failed_tests = np.array(data[data['Pass/Fail'] == 1].index)\n",
    "    no_failed_tests = len(failed_tests)\n",
    "\n",
    "    normal_indices = data[data['Pass/Fail'] == -1]\n",
    "    no_normal_indices = len(normal_indices)\n",
    "    \n",
    "    np.random.seed(10)\n",
    "    random_normal_indices = np.random.choice(no_normal_indices, size = no_failed_tests, replace = True)\n",
    "    random_normal_indices = np.array(random_normal_indices)\n",
    "\n",
    "    under_sample = np.concatenate([failed_tests, random_normal_indices])\n",
    "    undersample_data = data.iloc[under_sample, :]\n",
    "\n",
    "    x = undersample_data.iloc[:, undersample_data.columns != 'Pass/Fail'] \n",
    "    y = undersample_data.iloc[:, undersample_data.columns == 'Pass/Fail']\n",
    "    y = np.ravel(y)\n",
    "\n",
    "    x_train_us, x_test_us, y_train_us, y_test_us = train_test_split(x, y, test_size = 0.2, random_state = 4)\n",
    "    \n",
    "    print(\"학습용 데이터 크기: {}\".format(x_train_us.shape))\n",
    "    print(\"테스트용 데이터 크기: {}\".format(x_test_us.shape))\n",
    "    \n",
    "    return x_train_us, x_test_us, y_train_us, y_test_us\n",
    "\n",
    "def train(x_train_us, y_train_us):\n",
    "\n",
    "    print(\"학습을 수행합니다.\")\n",
    "    \n",
    "    model = XGBClassifier(random_state=2)\n",
    "    \n",
    "    # 파라미터 튜닝\n",
    "    parameters = [{'max_depth' : [1, 2, 3, 4, 5, 6]}]\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator = model, param_grid = parameters, scoring = 'recall', cv = 4, n_jobs = -1)\n",
    "    \n",
    "    \n",
    "    import pickle\n",
    "    \n",
    "    for j in trange(5000,file=sys.stdout, leave=False, unit_scale=True, desc='학습 진행률'):\n",
    "    \n",
    "        with open('model.pkl', 'rb') as f:\n",
    "             model = pickle.load(f)\n",
    "    print(\"학습 완료\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1220e5c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'machine'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-dad6b622471e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmachine\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \"\"\"\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'machine'"
     ]
    }
   ],
   "source": [
    "import machine as ma\n",
    "\n",
    "def main():\n",
    "    \n",
    "    \"\"\"\n",
    "    지시사항 1번. 데이터를 읽고 처리하는 코드를 작성해보세요.\n",
    "    \"\"\"\n",
    "    x_train_us, x_test_us, y_train_us, y_test_us = ma.preprocess()\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    지시사항 2번. 학습을 수행시켜보세요.\n",
    "    \"\"\"\n",
    "    model = ma.train(x_train_us, y_train_us)\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8e1915",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0fb034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "067cb99e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-eb146368e5d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# to avoid warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, average_precision_score\n",
    "\n",
    "from elice_utils import EliceUtils\n",
    "elice_utils = EliceUtils()\n",
    "\n",
    "def preprocess():\n",
    "\n",
    "    #print(\"데이터 읽는 중...\")\n",
    "    data = pd.read_csv('data/uci-secom.csv')\n",
    "    \n",
    "    #print(data.isnull().sum())\n",
    "    #print(\"결측 데이터 값을 처리합니다.\")\n",
    "    data = data.replace(np.NaN, 0)\n",
    "    #print(data.isnull().sum())\n",
    "    \n",
    "    # 쓸모없는 데이터 지우기\n",
    "    data = data.drop(columns = ['Time'], axis = 1)\n",
    "    \n",
    "    # 타겟 데이터 분리\n",
    "    x = data.iloc[:,:590]\n",
    "    y = data.iloc[:, 590]\n",
    "\n",
    "    #print(\"학습용 데이터와 테스트용 데이터로 분리 합니다.\")\n",
    "\n",
    "    # Under sampling 수행\n",
    "    failed_tests = np.array(data[data['Pass/Fail'] == 1].index)\n",
    "    no_failed_tests = len(failed_tests)\n",
    "\n",
    "    normal_indices = data[data['Pass/Fail'] == -1]\n",
    "    no_normal_indices = len(normal_indices)\n",
    "    \n",
    "    np.random.seed(10)\n",
    "    random_normal_indices = np.random.choice(no_normal_indices, size = no_failed_tests, replace = True)\n",
    "    random_normal_indices = np.array(random_normal_indices)\n",
    "\n",
    "    under_sample = np.concatenate([failed_tests, random_normal_indices])\n",
    "    undersample_data = data.iloc[under_sample, :]\n",
    "\n",
    "    x = undersample_data.iloc[:, undersample_data.columns != 'Pass/Fail'] \n",
    "    y = undersample_data.iloc[:, undersample_data.columns == 'Pass/Fail']\n",
    "    y = np.ravel(y)\n",
    "\n",
    "    x_train_us, x_test_us, y_train_us, y_test_us = train_test_split(x, y, test_size = 0.2, random_state = 4)\n",
    "    \n",
    "    #print(\"학습용 데이터 크기: {}\".format(x_train_us.shape))\n",
    "    #print(\"테스트용 데이터 크기: {}\".format(x_test_us.shape))\n",
    "    \n",
    "    return x_train_us, x_test_us, y_train_us, y_test_us\n",
    "    \n",
    "    \n",
    "def train(x_train_us, y_train_us):\n",
    "\n",
    "    \"\"\"\n",
    "    #print(\"학습을 수행합니다.\")\n",
    "    \n",
    "    model = XGBClassifier(random_state=2)\n",
    "    \n",
    "    # 파라미터 튜닝\n",
    "    parameters = [{'max_depth' : [1, 2, 3, 4, 5, 6]}]\n",
    "\n",
    "    grid_search = GridSearchCV(estimator = model, param_grid = parameters, scoring = 'recall', cv = 4, n_jobs = -1)\n",
    "\n",
    "    grid_search = grid_search.fit(x_train_us, y_train_us)\n",
    "    \n",
    "    # 베스트 모델 선택\n",
    "    model = grid_search.best_estimator_\n",
    "    \"\"\"\n",
    "    import pickle\n",
    "    \n",
    "    with open('model.pkl', 'rb') as f:\n",
    "         model = pickle.load(f)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "def evaluation():\n",
    "\n",
    "    x_train_us, x_test_us, y_train_us, y_test_us = preprocess()\n",
    "    model = train(x_train_us, y_train_us)\n",
    "    # 테스트 데이터 예측\n",
    "    y_pred = model.predict(x_test_us)\n",
    "    print('평가 지표인 recall score를 출력합니다.: ', recall_score(y_test_us, y_pred), '\\n')\n",
    "    \n",
    "    print(\"센서들의 중요도를 출력합니다.\")\n",
    "    xgb.plot_importance(model, height = 1, grid = True, importance_type = 'gain', show_values = False, max_num_features = 20)\n",
    "\n",
    "    plt.rcParams['figure.figsize'] = (10, 15)\n",
    "    plt.xlabel('The importance score for each features')\n",
    "    plt.ylabel('Features')\n",
    "    \n",
    "    plt.savefig(\"result1.png\")\n",
    "    elice_utils.send_image(\"result1.png\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecf8cb71",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'machine'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-cd141205e789>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmachine\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \"\"\"\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'machine'"
     ]
    }
   ],
   "source": [
    "import machine as ma\n",
    "\n",
    "def main():\n",
    "    \n",
    "    \"\"\"\n",
    "    지시사항 1번. 예측 정확도 결과를 출력해보세요.\n",
    "    \"\"\"\n",
    "    ma.evaluation()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c31bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d31503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "839433d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-ee01f541cc12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# to avoid warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, average_precision_score\n",
    "\n",
    "from elice_utils import EliceUtils\n",
    "elice_utils = EliceUtils()\n",
    "\n",
    "def preprocess():\n",
    "\n",
    "    #print(\"데이터 읽는 중...\")\n",
    "    data = pd.read_csv('data/uci-secom.csv')\n",
    "    \n",
    "    #print(data.isnull().sum())\n",
    "    #print(\"결측 데이터 값을 처리합니다.\")\n",
    "    data = data.replace(np.NaN, 0)\n",
    "    #print(data.isnull().sum())\n",
    "    \n",
    "    # 쓸모없는 데이터 지우기\n",
    "    data = data.drop(columns = ['Time'], axis = 1)\n",
    "    \n",
    "    # 타겟 데이터 분리\n",
    "    x = data.iloc[:,:590]\n",
    "    y = data.iloc[:, 590]\n",
    "\n",
    "    #print(\"학습용 데이터와 테스트용 데이터로 분리 합니다.\")\n",
    "\n",
    "    # Under sampling 수행\n",
    "    failed_tests = np.array(data[data['Pass/Fail'] == 1].index)\n",
    "    no_failed_tests = len(failed_tests)\n",
    "\n",
    "    normal_indices = data[data['Pass/Fail'] == -1]\n",
    "    no_normal_indices = len(normal_indices)\n",
    "    \n",
    "    np.random.seed(10)\n",
    "    random_normal_indices = np.random.choice(no_normal_indices, size = no_failed_tests, replace = True)\n",
    "    random_normal_indices = np.array(random_normal_indices)\n",
    "\n",
    "    under_sample = np.concatenate([failed_tests, random_normal_indices])\n",
    "    undersample_data = data.iloc[under_sample, :]\n",
    "\n",
    "    x = undersample_data.iloc[:, undersample_data.columns != 'Pass/Fail'] \n",
    "    y = undersample_data.iloc[:, undersample_data.columns == 'Pass/Fail']\n",
    "    y = np.ravel(y)\n",
    "\n",
    "    x_train_us, x_test_us, y_train_us, y_test_us = train_test_split(x, y, test_size = 0.2, random_state = 4)\n",
    "    \n",
    "    #print(\"학습용 데이터 크기: {}\".format(x_train_us.shape))\n",
    "    #print(\"테스트용 데이터 크기: {}\".format(x_test_us.shape))\n",
    "    \n",
    "    return x_train_us, x_test_us, y_train_us, y_test_us, data\n",
    "    \n",
    "    \n",
    "def train(x_train_us, y_train_us):\n",
    "\n",
    "    \"\"\"\n",
    "    #print(\"학습을 수행합니다.\")\n",
    "    \n",
    "    model = XGBClassifier(random_state=2)\n",
    "    \n",
    "    # 파라미터 튜닝\n",
    "    parameters = [{'max_depth' : [1, 2, 3, 4, 5, 6]}]\n",
    "\n",
    "    grid_search = GridSearchCV(estimator = model, param_grid = parameters, scoring = 'recall', cv = 4, n_jobs = -1)\n",
    "\n",
    "    grid_search = grid_search.fit(x_train_us, y_train_us)\n",
    "    \n",
    "    # 베스트 모델 선택\n",
    "    model = grid_search.best_estimator_\n",
    "    \"\"\"\n",
    "    import pickle\n",
    "    \n",
    "    with open('model.pkl', 'rb') as f:\n",
    "         model = pickle.load(f)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "def predict(value_103_sensor):\n",
    "\n",
    "    x_train_us, x_test_us, y_train_us, y_test_us, data = preprocess()\n",
    "    model = train(x_train_us, y_train_us)\n",
    "    \n",
    "    pre_data = data\n",
    "    pre_data.loc[1242, '103'] = value_103_sensor\n",
    "    pre_data = pre_data[1242:1243]\n",
    "    \n",
    "    prediction = model.predict(pre_data.drop(columns = 'Pass/Fail'))\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    sns.distplot(data['103'], color = 'darkblue')\n",
    "    plt.title('103 Sensor Measurements', fontsize = 20)\n",
    "    \n",
    "    ax.annotate('103_sensor_value',\n",
    "            xy=(value_103_sensor, 0), xycoords='data',\n",
    "            xytext=(10, 30), textcoords='offset points',\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "            horizontalalignment='left', verticalalignment='bottom')\n",
    "    \n",
    "    plt.savefig(\"result1.png\")\n",
    "    elice_utils.send_image(\"result1.png\")\n",
    "    \n",
    "    if prediction == 1:\n",
    "    \n",
    "        print(\"103 센서 데이터 값이 {}인 경우 공정 이상이 발생할 것으로 예측됩니다.\".format(value_103_sensor))\n",
    "    else:\n",
    "        print(\"103 센서 데이터 값이 {}인 경우 공정 이상이 발생하지 않을 것으로 예측됩니다.\".format(value_103_sensor))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cd61e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import machine as ma\n",
    "\n",
    "def main():\n",
    "\t\n",
    "    \"\"\"\n",
    "    지시사항 1번. 103번 센서값인 아래의 value_103_sensor 값을 바꾸어보세요.\n",
    "    \"\"\"\n",
    "    value_103_sensor = -0.03\n",
    "    \n",
    "    # 예측을 진행하는 코드입니다.\n",
    "    ma.predict(value_103_sensor)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
